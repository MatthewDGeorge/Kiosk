{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please install the required Python modules/SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "! activate ai-azure-c1\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/opt/conda/envs/ai-azure-c1/lib/python3.8/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Custom Vision - Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import utility functions and Python modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, time, uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_in_cell(img_url):\n",
    "    response = requests.get(img_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "- Azure Custom Vision Endpoint\n",
    "- Training Reource ID and Key\n",
    "- Prediction Resource ID and Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure you have the correct Training and Prediction Endpoints, Keys and Resource IDs separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Training Endpoint resource must be for both training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_ENDPOINT = \"https://vision244721.cognitiveservices.azure.com/\"\n",
    "training_key = \"8b3070d0b1804ca3824f6eb7ff9642f0\"\n",
    "training_resource_id = \"/subscriptions/e144b1f9-a885-4518-b6ed-b2f3026e2a17/resourceGroups/ODL-AIND-244721/providers/Microsoft.CognitiveServices/accounts/vision244721\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_ENDPOINT = \"https://vision244721-prediction.cognitiveservices.azure.com/\"\n",
    "prediction_key = \"49a5da8324da4f07a7d84a2fb4c26e70\"\n",
    "prediction_resource_id = \"/subscriptions/e144b1f9-a885-4518-b6ed-b2f3026e2a17/resourceGroups/ODL-AIND-244721/providers/Microsoft.CognitiveServices/accounts/vision244721-Prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and authenticate the training client with endpoint and key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(TRAINING_ENDPOINT, training_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4-preview'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and authenticate the prediction client with endpoint and key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(PREDICTION_ENDPOINT, prediction_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Project First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Object Detection Training project has been created. Please move on.\n"
     ]
    }
   ],
   "source": [
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "\n",
    "# Create a new project\n",
    "print (\"Your Object Detection Training project has been created. Please move on.\")\n",
    "project_name = uuid.uuid4()\n",
    "project = trainer.create_project(project_name, domain_id=obj_detection_domain.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Project Details as collective information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'e045b25d-aa6a-4423-805e-44398a6b0eb1',\n",
       " 'name': 'e2722582-9ea7-492d-8bd4-94dc9857e524',\n",
       " 'description': '',\n",
       " 'settings': {'domain_id': 'da2e3a8a-40a5-4171-82f4-58522f70fbc1',\n",
       "  'classification_type': 'Multilabel',\n",
       "  'target_export_platforms': [],\n",
       "  'use_negative_set': True,\n",
       "  'image_processing_settings': {'augmentation_methods': {'rotation': True,\n",
       "    'scaling': True,\n",
       "    'translation': True,\n",
       "    'horizontal flip': True,\n",
       "    'equalize': True,\n",
       "    'solarize': True,\n",
       "    'padtosquare': True}}},\n",
       " 'created': '2023-12-04T00:23:43.160Z',\n",
       " 'last_modified': '2023-12-04T00:23:43.160Z',\n",
       " 'dr_mode_enabled': False,\n",
       " 'status': 'Succeeded'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Tags based on training requirements\n",
    "  \n",
    "- In the demo, we used images and tags for Bird and Flower. For this exercise, you can use the \"bottle\" tag or any other class/type of your own images.\n",
    "- Please modify the code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lighter_tag = trainer.create_tag(project.id, \"lighter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flower_tag = trainer.create_tag(project.id, \"Flower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERY IMPORTANT - PAUSE HERE\n",
    "# Now, please go to the Custom Vision portal, upload and label your training images\n",
    "## Please read the following instructions:\n",
    "\n",
    "- Please visit the Custom Vision Portal (https://computervision.api) and upload all your training images manually. \n",
    "- After that, you can label the tag region for each object directly at the portal. \n",
    "- This way, you don't need to use any third-party website or service to generate tag regions in the form of bounding box coordinates. If you have training images with those coordinates, you can use the optional section in the demo Jupyter Notebook to upload your images with the tagged objects via code.\n",
    "\n",
    "### Once you have uploaded and labeled all the training images at the portal, you can come back to this notebook and start the training process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Object Detection Training\n",
    "- We will keep checking every 10 seconds during the training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Completed\n",
      "Waiting 10 seconds...\n"
     ]
    }
   ],
   "source": [
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    print (\"Waiting 10 seconds...\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After training is complete, we will check model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '418da9a8-e6f8-4dfd-9c2a-f77ff430b6e3',\n",
       " 'name': 'Iteration 1',\n",
       " 'status': 'Completed',\n",
       " 'created': '2023-12-04T00:23:43.163Z',\n",
       " 'last_modified': '2023-12-04T00:32:33.426Z',\n",
       " 'trained_at': '2023-12-04T00:32:33.423Z',\n",
       " 'project_id': 'e045b25d-aa6a-4423-805e-44398a6b0eb1',\n",
       " 'exportable': False,\n",
       " 'domain_id': 'da2e3a8a-40a5-4171-82f4-58522f70fbc1',\n",
       " 'training_type': 'Regular',\n",
       " 'reserved_budget_in_hours': 0,\n",
       " 'training_time_in_minutes': 2}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'id': '375c2bb8-9681-4fc8-9a43-4bccf72e8e72', 'name': 'Iteration 6', 'status': 'Completed', 'created': datetime.datetime(2023, 12, 4, 1, 11, 7, 903000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'last_modified': datetime.datetime(2023, 12, 4, 1, 24, 6, 681000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'trained_at': datetime.datetime(2023, 12, 4, 1, 24, 6, 678000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'project_id': 'e045b25d-aa6a-4423-805e-44398a6b0eb1', 'exportable': False, 'exportable_to': None, 'domain_id': 'da2e3a8a-40a5-4171-82f4-58522f70fbc1', 'classification_type': None, 'training_type': 'Regular', 'reserved_budget_in_hours': 0, 'training_time_in_minutes': 2, 'publish_name': None, 'original_publish_resource_id': None, 'custom_base_model_info': None, 'training_error_details': None}\n",
      "{'additional_properties': {}, 'id': 'b5903e52-fbeb-4fbf-b29f-18a804ec45b1', 'name': 'Iteration 5', 'status': 'Completed', 'created': datetime.datetime(2023, 12, 4, 1, 3, 9, 803000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'last_modified': datetime.datetime(2023, 12, 4, 1, 15, 39, 139000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'trained_at': datetime.datetime(2023, 12, 4, 1, 15, 39, 136000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'project_id': 'e045b25d-aa6a-4423-805e-44398a6b0eb1', 'exportable': False, 'exportable_to': None, 'domain_id': 'da2e3a8a-40a5-4171-82f4-58522f70fbc1', 'classification_type': None, 'training_type': 'Regular', 'reserved_budget_in_hours': 0, 'training_time_in_minutes': 2, 'publish_name': None, 'original_publish_resource_id': None, 'custom_base_model_info': None, 'training_error_details': None}\n",
      "{'additional_properties': {}, 'id': 'bd29f1ae-2526-48d8-b92c-6ccbe336c0f9', 'name': 'Iteration 4', 'status': 'Completed', 'created': datetime.datetime(2023, 12, 4, 0, 49, 59, 196000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'last_modified': datetime.datetime(2023, 12, 4, 1, 7, 38, 527000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'trained_at': datetime.datetime(2023, 12, 4, 1, 7, 38, 524000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'project_id': 'e045b25d-aa6a-4423-805e-44398a6b0eb1', 'exportable': False, 'exportable_to': None, 'domain_id': 'da2e3a8a-40a5-4171-82f4-58522f70fbc1', 'classification_type': None, 'training_type': 'Regular', 'reserved_budget_in_hours': 0, 'training_time_in_minutes': 2, 'publish_name': None, 'original_publish_resource_id': None, 'custom_base_model_info': None, 'training_error_details': None}\n",
      "{'additional_properties': {}, 'id': '35764f11-8df1-442f-8390-ed47bf8f75d7', 'name': 'Iteration 3', 'status': 'Completed', 'created': datetime.datetime(2023, 12, 4, 0, 38, 9, 213000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'last_modified': datetime.datetime(2023, 12, 4, 0, 54, 25, 634000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'trained_at': datetime.datetime(2023, 12, 4, 0, 54, 25, 631000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'project_id': 'e045b25d-aa6a-4423-805e-44398a6b0eb1', 'exportable': False, 'exportable_to': None, 'domain_id': 'da2e3a8a-40a5-4171-82f4-58522f70fbc1', 'classification_type': None, 'training_type': 'Regular', 'reserved_budget_in_hours': 0, 'training_time_in_minutes': 2, 'publish_name': None, 'original_publish_resource_id': None, 'custom_base_model_info': None, 'training_error_details': None}\n",
      "{'additional_properties': {}, 'id': '1d5371e0-8a71-45ef-aee8-ff98d5491a39', 'name': 'Iteration 2', 'status': 'Completed', 'created': datetime.datetime(2023, 12, 4, 0, 28, 6, 436000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'last_modified': datetime.datetime(2023, 12, 4, 0, 42, 41, 177000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'trained_at': datetime.datetime(2023, 12, 4, 0, 42, 41, 174000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'project_id': 'e045b25d-aa6a-4423-805e-44398a6b0eb1', 'exportable': False, 'exportable_to': None, 'domain_id': 'da2e3a8a-40a5-4171-82f4-58522f70fbc1', 'classification_type': None, 'training_type': 'Regular', 'reserved_budget_in_hours': 0, 'training_time_in_minutes': 2, 'publish_name': None, 'original_publish_resource_id': None, 'custom_base_model_info': None, 'training_error_details': None}\n",
      "{'additional_properties': {}, 'id': '418da9a8-e6f8-4dfd-9c2a-f77ff430b6e3', 'name': 'Iteration 1', 'status': 'Completed', 'created': datetime.datetime(2023, 12, 4, 0, 23, 43, 163000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'last_modified': datetime.datetime(2023, 12, 4, 0, 32, 33, 426000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'trained_at': datetime.datetime(2023, 12, 4, 0, 32, 33, 423000, tzinfo=<isodate.tzinfo.Utc object at 0x7f9a90de62e8>), 'project_id': 'e045b25d-aa6a-4423-805e-44398a6b0eb1', 'exportable': False, 'exportable_to': None, 'domain_id': 'da2e3a8a-40a5-4171-82f4-58522f70fbc1', 'classification_type': None, 'training_type': 'Regular', 'reserved_budget_in_hours': 0, 'training_time_in_minutes': 2, 'publish_name': None, 'original_publish_resource_id': None, 'custom_base_model_info': None, 'training_error_details': None}\n"
     ]
    }
   ],
   "source": [
    "iteration_list = trainer.get_iterations(project.id)\n",
    "for iteration_item in iteration_list:\n",
    "    print(iteration_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf = trainer.get_iteration_performance(project.id, iteration_list[5].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'per_tag_performance': [{'id': '04f2eb59-a9db-425b-be13-4e324b579698',\n",
       "   'name': 'lighter',\n",
       "   'precision': 1.0,\n",
       "   'precision_std_deviation': 0.0,\n",
       "   'recall': 0.25,\n",
       "   'recall_std_deviation': 0.0,\n",
       "   'average_precision': 0.9166667}],\n",
       " 'precision': 1.0,\n",
       " 'precision_std_deviation': 0.0,\n",
       " 'recall': 0.25,\n",
       " 'recall_std_deviation': 0.0,\n",
       " 'average_precision': 0.9166667}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perf.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishing the Model to the Project Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the Iteration Name, this will be used when Model training is completed\n",
    "publish_iteration_name = \"lighter_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# The iteration is now trained. Publish it to the project endpoint\n",
    "trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Prediction\n",
    "- Using the predictor object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lighter_model'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_iteration_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_path = '/home/workspace/lighter_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lighter_test_set_1of5.jpg  lighter_test_set_3of5.jpg  lighter_test_set_5of5.jpg\r\n",
      "lighter_test_set_2of5.jpg  lighter_test_set_4of5.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls $local_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prediction(image_file_name):\n",
    "    with open(os.path.join (local_image_path,  image_file_name), \"rb\") as image_contents:\n",
    "        results = predictor.detect_image(project.id, publish_iteration_name, image_contents.read())\n",
    "        # Display the results.\n",
    "        print(image_file_name)\n",
    "        for prediction in results.predictions:\n",
    "            if prediction.probability > 0.1:\n",
    "                print(\"\\t\" + prediction.tag_name +\n",
    "                      \": {0:.2f}%\".format(prediction.probability * 100))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform_prediction('lighter_test_set_1of5.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lighter_test_set_1of5.jpg\n",
      "\tlighter: 70.92%\n",
      "\tlighter: 37.24%\n",
      "\tlighter: 10.72%\n",
      "lighter_test_set_2of5.jpg\n",
      "\tlighter: 39.61%\n",
      "\tlighter: 38.83%\n",
      "\tlighter: 33.62%\n",
      "\tlighter: 13.17%\n",
      "\tlighter: 11.34%\n",
      "\tlighter: 10.86%\n",
      "lighter_test_set_3of5.jpg\n",
      "\tlighter: 67.09%\n",
      "\tlighter: 27.05%\n",
      "lighter_test_set_4of5.jpg\n",
      "\tlighter: 56.19%\n",
      "\tlighter: 22.56%\n",
      "\tlighter: 12.19%\n",
      "lighter_test_set_5of5.jpg\n",
      "\tlighter: 16.26%\n",
      "\tlighter: 14.93%\n",
      "\tlighter: 10.84%\n",
      "\tlighter: 10.45%\n"
     ]
    }
   ],
   "source": [
    "for test in range(1, 6):\n",
    "    image_file_name = 'lighter_test_set_{}of5.jpg'.format(test)\n",
    "    perform_prediction(image_file_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
